---
title: "Cleaning Datasets"
author: "Tim Trice"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Cleaning Datasets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = TRUE, 
                      comment = "#>", 
                      fig.width = 7)
```

```{r, echo = FALSE, message = FALSE}
library(NCDCStormEvents)
library(data.table)
library(ggplot2)
library(maps)
```

## Dates and Times

The date and time variables in this dataset are, honestly, quite horrible. In the `details` dataset alone there are 11 variables for date and time where we only need one. 

But we don't want to delete those variables or edit them. Instead, we want to create lookup tables. Remember, `EVENT_ID` serves as our key so we can tie in any dataset by `EVENT_ID` alone. 

With that, we can start a rather arduous process of cleaning the dates and times. First, we want to start with time zones. 

## Time Zones

In my exploratory processes with this dataset, working with the time zones has been a bit of a nightmare. Let's take a sample look:

```{r}
DT <- get_data(1965, "details")

unique(DT$CZ_TIMEZONE)

tz_to_dt(DT[, .(EVENT_ID, CZ_TIMEZONE)])
```

This doesn't seem too bad. Let's dig a bit deeper.

`MDT` has one row; let's check it out.

```{r, fig.asp = 0.5}
tmp <- DT[MDT, .(EVENT_ID, CZ_NAME, STATE, CZ_TIMEZONE, BEGIN_LAT, 
                 BEGIN_LON)]

US <- map_data("state")

bp <- list(geom_polygon(data = US, aes(x = long, y = lat, group = group), 
                 colour = "grey10", fill = "white"), 
           geom_point(size = 1, colour = "red"))

ggplot(tmp, aes(x = BEGIN_LON, y = BEGIN_LAT)) + bp
```

Well, that doesn't seem right...

```{r}
tmp
```

So, our city - Brookings, SD is actually in the central time zone according to [TimeAndDate.com](http://www.timeanddate.com/worldclock/usa/sioux-falls). 

Maybe it's something in my code? Let's just pull straight from `DT`.

```{r, fig.asp = 0.5}
tmp <- DT[CZ_TIMEZONE == "MDT", .(EVENT_ID, CZ_NAME, STATE, CZ_TIMEZONE, 
                                  BEGIN_LAT, BEGIN_LON)]
ggplot(tmp, aes(x = BEGIN_LON, y = BEGIN_LAT)) + bp

tmp
```

So far not so good. What about `EST`?

```{r}
tmp <- DT[EST, .(EVENT_ID, CZ_NAME, STATE, CZ_TIMEZONE, BEGIN_LAT, BEGIN_LON)]

ggplot(tmp, aes(x = BEGIN_LON, y = BEGIN_LAT)) + bp
```

Ah, geez....

I'm afraid to ask about `CST`.

```{r, fig.asp = 0.7}
tmp <- DT[CST, .(EVENT_ID, CZ_NAME, STATE, CZ_TIMEZONE, BEGIN_LAT, BEGIN_LON)]

ggplot(tmp, aes(x = BEGIN_LON, y = BEGIN_LAT)) + bp
```

Wow!

So we cannot rely on the timezone data in these datasets! Luckily for us, we have other options.

We have access to a FIPS dataset that gives us some of the same information we already have in our `details` dataset. But, hopefully, more accurate. Let's look at EST:

```{r, fig.asp = 0.5}
fips <- fips_dt()

tmp <- fips[TIME_ZONE == "E", .(LAT, LON)]

ggplot(tmp, aes(x = LON, y = LAT)) + bp
```

*This* is what we expect! 

Now, something to note regardings the `fips_dt()`. You may notice we filtered our data.table by `TIME_ZONE == 'E'` for Eastern Time. 

1. `TIME_ZONE` is a two-character field. Most of the values will be one character. But, there are instances where a FIPS code falls along two time zones. How you choose to handle that is up to you. Being that, in general, weather systems move west to east, it may not be a bad idea to choose the easternmost timezone. Something to consider.

2. The values of `TIME_ZONE` are stored in `fips_tz_abbr()`:

```{r}
fips_tz_abbr()
```

## Merge FIPS and Details

Let's work on a sample `details` dataset where `year == 1965` and get our fips dataset:

```{r}
DT <- get_data(1965, type = "details")
Fips <- fips_dt()
```

Let's filter out the variables we need to rebuild date/time variables. We can recall these variables with `datetime_fields()`:

```{r}
datetime_fields()
```

We'll also need `DT$CZ_FIPS` and `DT$STATE_FIPS` so I'll add that to the vector.

```{r}
vars <- c(datetime_fields(), "CZ_FIPS", "STATE_FIPS")

tmp <- DT[, vars, with = FALSE]
```

Now, [FIPS county code's](https://en.wikipedia.org/wiki/FIPS_county_code) are five digits. You may notice in `Fips` this is correct. However, in our `DT` and `tmp` data.table's they're split into `CZ_FIPS` and `STATE_FIPS`. So, I'll add a new variable to our `tmp` data.table called `FIPS` (I like it simple). 

```{r}
tmp[, FIPS := sprintf("%02d%03d", STATE_FIPS, CZ_FIPS)]
```

Now we can `setkeys()` and merge our data.tables into a new one I'll name `clean`. 

```{r}
setkey(tmp, FIPS)
setkey(Fips, FIPS)
clean <- Fips[tmp, mult = "first"]
```

Now, what unique `TIME_ZONE` do we have?

```{r}
unique(clean$TIME_ZONE)
```

If we look at our documentation for `fips_tz_abbr()` we see the following:

* V   Atlantic Standard

* E   Eastern Standard (e = advanced time not observed)

* C   Central Standard

* M   Mountain Standard (m = advanced time not observed)

* P   Pacific Standard

* A   Alaska Standard

* H   Hawaii-Aleutian Standard

* G   Guam & Marianas

* S   Samoa Standard

So, we have 10 unique time zones (one `NA`) and two in multiple time zones (`MP` and `CM`). Again, the multiples are discretionary. My personal rule with this is to assign the easternmost time zone. So, for `MP` I'll assign `M` or *MST* and for `CM` I'll assign *CST*. 

```{r}
clean[TIME_ZONE %in% "MP", TIME_ZONE := "M"]
clean[TIME_ZONE %in% "CM", TIME_ZONE := "C"]
```

Regarding if "advanced time not observed", I'm not sure how to handle this at the moment. For now, I'll ignore it beyond making them upper-case.

```{r}
clean$TIME_ZONE <- toupper(clean$TIME_ZONE)
```

And now I'll add `TZ` for the timezone abbreviation.

```{r}
time_zones <- fips_tz_abbr()

# Not sure I like handling it this way... print str()
clean[, TZ := time_zones[TIME_ZONE]]
```

## Create Datetime Variable

